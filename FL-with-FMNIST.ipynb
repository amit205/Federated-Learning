{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy  # import the Pysyft library\n",
    "hook = sy.TorchHook(torch)  # hook PyTorch ie add extra functionalities to support Federated Learning\n",
    "vw1 = sy.VirtualWorker(hook, id=\"vw1\")  # define remote worker vw1\n",
    "vw2 = sy.VirtualWorker(hook, id=\"vw2\")  # and vw2\n",
    "vw3 = sy.VirtualWorker(hook, id=\"vw3\")\n",
    "vw4 = sy.VirtualWorker(hook, id=\"vw4\")\n",
    "vw5 = sy.VirtualWorker(hook, id=\"vw5\")\n",
    "vw6 = sy.VirtualWorker(hook, id=\"vw6\")\n",
    "vw7 = sy.VirtualWorker(hook, id=\"vw7\")\n",
    "vw8 = sy.VirtualWorker(hook, id=\"vw8\")\n",
    "vw9 = sy.VirtualWorker(hook, id=\"vw9\")\n",
    "vw0 = sy.VirtualWorker(hook, id=\"vw0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vw_crypto = sy.VirtualWorker(hook, id='vw_crypto' )\n",
    "secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_nodes = [vw0, vw1, vw2, vw3, vw4, vw5, vw6, vw7, vw8, vw9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.test_batch_size = 1000\n",
    "        self.epochs = epochs\n",
    "        self.lr = 0.01\n",
    "        self.momentum = 0.5\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 30\n",
    "        self.save_model = False\n",
    "\n",
    "args = Arguments()\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The following options are not supported: num_workers: 1, pin_memory: True\n"
     ]
    }
   ],
   "source": [
    "federated_train_loader = sy.FederatedDataLoader( # this is now a FederatedDataLoader \n",
    "    datasets.FashionMNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "    .federate((vw1, vw2, vw3, vw4, vw5, vw6, vw7, vw8, vw9, vw0)), # we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No aggregation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, federated_train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(federated_train_loader): # now it is a distributed dataset\n",
    "        model.send(data.location) # send the model to the right location\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.get() # get the model back\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            loss = loss.get() # get the loss back\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,\n",
    "                100. * batch_idx / len(federated_train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60032 (0%)]\tLoss: 2.312420\n",
      "Train Epoch: 1 [1920/60032 (3%)]\tLoss: 2.123379\n",
      "Train Epoch: 1 [3840/60032 (6%)]\tLoss: 1.819058\n",
      "Train Epoch: 1 [5760/60032 (10%)]\tLoss: 1.408664\n",
      "Train Epoch: 1 [7680/60032 (13%)]\tLoss: 1.095940\n",
      "Train Epoch: 1 [9600/60032 (16%)]\tLoss: 1.141997\n",
      "Train Epoch: 1 [11520/60032 (19%)]\tLoss: 0.956914\n",
      "Train Epoch: 1 [13440/60032 (22%)]\tLoss: 0.939769\n",
      "Train Epoch: 1 [15360/60032 (26%)]\tLoss: 1.041346\n",
      "Train Epoch: 1 [17280/60032 (29%)]\tLoss: 0.871910\n",
      "Train Epoch: 1 [19200/60032 (32%)]\tLoss: 0.881196\n",
      "Train Epoch: 1 [21120/60032 (35%)]\tLoss: 0.893526\n",
      "Train Epoch: 1 [23040/60032 (38%)]\tLoss: 0.961888\n",
      "Train Epoch: 1 [24960/60032 (42%)]\tLoss: 0.829886\n",
      "Train Epoch: 1 [26880/60032 (45%)]\tLoss: 0.923244\n",
      "Train Epoch: 1 [28800/60032 (48%)]\tLoss: 0.791858\n",
      "Train Epoch: 1 [30720/60032 (51%)]\tLoss: 0.730345\n",
      "Train Epoch: 1 [32640/60032 (54%)]\tLoss: 0.639516\n",
      "Train Epoch: 1 [34560/60032 (58%)]\tLoss: 0.746028\n",
      "Train Epoch: 1 [36480/60032 (61%)]\tLoss: 0.722750\n",
      "Train Epoch: 1 [38400/60032 (64%)]\tLoss: 0.721465\n",
      "Train Epoch: 1 [40320/60032 (67%)]\tLoss: 0.803968\n",
      "Train Epoch: 1 [42240/60032 (70%)]\tLoss: 0.688300\n",
      "Train Epoch: 1 [44160/60032 (74%)]\tLoss: 0.612809\n",
      "Train Epoch: 1 [46080/60032 (77%)]\tLoss: 0.522129\n",
      "Train Epoch: 1 [48000/60032 (80%)]\tLoss: 0.645042\n",
      "Train Epoch: 1 [49920/60032 (83%)]\tLoss: 1.067957\n",
      "Train Epoch: 1 [51840/60032 (86%)]\tLoss: 0.552676\n",
      "Train Epoch: 1 [53760/60032 (90%)]\tLoss: 0.769798\n",
      "Train Epoch: 1 [55680/60032 (93%)]\tLoss: 0.616617\n",
      "Train Epoch: 1 [57600/60032 (96%)]\tLoss: 0.577511\n",
      "Train Epoch: 1 [59520/60032 (99%)]\tLoss: 0.748155\n",
      "\n",
      "Test set: Average loss: 0.6480, Accuracy: 7522/10000 (75%)\n",
      "\n",
      "Train Epoch: 2 [0/60032 (0%)]\tLoss: 0.628335\n",
      "Train Epoch: 2 [1920/60032 (3%)]\tLoss: 0.509867\n",
      "Train Epoch: 2 [3840/60032 (6%)]\tLoss: 0.600559\n",
      "Train Epoch: 2 [5760/60032 (10%)]\tLoss: 0.581747\n",
      "Train Epoch: 2 [7680/60032 (13%)]\tLoss: 0.469825\n",
      "Train Epoch: 2 [9600/60032 (16%)]\tLoss: 0.611633\n",
      "Train Epoch: 2 [11520/60032 (19%)]\tLoss: 0.490750\n",
      "Train Epoch: 2 [13440/60032 (22%)]\tLoss: 0.615690\n",
      "Train Epoch: 2 [15360/60032 (26%)]\tLoss: 0.666598\n",
      "Train Epoch: 2 [17280/60032 (29%)]\tLoss: 0.284293\n",
      "Train Epoch: 2 [19200/60032 (32%)]\tLoss: 0.453634\n",
      "Train Epoch: 2 [21120/60032 (35%)]\tLoss: 0.522822\n",
      "Train Epoch: 2 [23040/60032 (38%)]\tLoss: 0.583711\n",
      "Train Epoch: 2 [24960/60032 (42%)]\tLoss: 0.568499\n",
      "Train Epoch: 2 [26880/60032 (45%)]\tLoss: 0.506953\n",
      "Train Epoch: 2 [28800/60032 (48%)]\tLoss: 0.608666\n",
      "Train Epoch: 2 [30720/60032 (51%)]\tLoss: 0.528223\n",
      "Train Epoch: 2 [32640/60032 (54%)]\tLoss: 0.515901\n",
      "Train Epoch: 2 [34560/60032 (58%)]\tLoss: 0.491359\n",
      "Train Epoch: 2 [36480/60032 (61%)]\tLoss: 0.432553\n",
      "Train Epoch: 2 [38400/60032 (64%)]\tLoss: 0.520154\n",
      "Train Epoch: 2 [40320/60032 (67%)]\tLoss: 0.464821\n",
      "Train Epoch: 2 [42240/60032 (70%)]\tLoss: 0.568814\n",
      "Train Epoch: 2 [44160/60032 (74%)]\tLoss: 0.460225\n",
      "Train Epoch: 2 [46080/60032 (77%)]\tLoss: 0.499106\n",
      "Train Epoch: 2 [48000/60032 (80%)]\tLoss: 0.602472\n",
      "Train Epoch: 2 [49920/60032 (83%)]\tLoss: 0.558830\n",
      "Train Epoch: 2 [51840/60032 (86%)]\tLoss: 0.589287\n",
      "Train Epoch: 2 [53760/60032 (90%)]\tLoss: 0.580083\n",
      "Train Epoch: 2 [55680/60032 (93%)]\tLoss: 0.464545\n",
      "Train Epoch: 2 [57600/60032 (96%)]\tLoss: 0.461047\n",
      "Train Epoch: 2 [59520/60032 (99%)]\tLoss: 0.417482\n",
      "\n",
      "Test set: Average loss: 0.5213, Accuracy: 8123/10000 (81%)\n",
      "\n",
      "Train Epoch: 3 [0/60032 (0%)]\tLoss: 0.477216\n",
      "Train Epoch: 3 [1920/60032 (3%)]\tLoss: 0.454460\n",
      "Train Epoch: 3 [3840/60032 (6%)]\tLoss: 0.493406\n",
      "Train Epoch: 3 [5760/60032 (10%)]\tLoss: 0.401988\n",
      "Train Epoch: 3 [7680/60032 (13%)]\tLoss: 0.459681\n",
      "Train Epoch: 3 [9600/60032 (16%)]\tLoss: 0.562081\n",
      "Train Epoch: 3 [11520/60032 (19%)]\tLoss: 0.530532\n",
      "Train Epoch: 3 [13440/60032 (22%)]\tLoss: 0.581732\n",
      "Train Epoch: 3 [15360/60032 (26%)]\tLoss: 0.537448\n",
      "Train Epoch: 3 [17280/60032 (29%)]\tLoss: 0.401800\n",
      "Train Epoch: 3 [19200/60032 (32%)]\tLoss: 0.555872\n",
      "Train Epoch: 3 [21120/60032 (35%)]\tLoss: 0.460011\n",
      "Train Epoch: 3 [23040/60032 (38%)]\tLoss: 0.420932\n",
      "Train Epoch: 3 [24960/60032 (42%)]\tLoss: 0.392928\n",
      "Train Epoch: 3 [26880/60032 (45%)]\tLoss: 0.598777\n",
      "Train Epoch: 3 [28800/60032 (48%)]\tLoss: 0.299096\n",
      "Train Epoch: 3 [30720/60032 (51%)]\tLoss: 0.467887\n",
      "Train Epoch: 3 [32640/60032 (54%)]\tLoss: 0.388233\n",
      "Train Epoch: 3 [34560/60032 (58%)]\tLoss: 0.535066\n",
      "Train Epoch: 3 [36480/60032 (61%)]\tLoss: 0.406023\n",
      "Train Epoch: 3 [38400/60032 (64%)]\tLoss: 0.569535\n",
      "Train Epoch: 3 [40320/60032 (67%)]\tLoss: 0.398185\n",
      "Train Epoch: 3 [42240/60032 (70%)]\tLoss: 0.697422\n",
      "Train Epoch: 3 [44160/60032 (74%)]\tLoss: 0.602227\n",
      "Train Epoch: 3 [46080/60032 (77%)]\tLoss: 0.459557\n",
      "Train Epoch: 3 [48000/60032 (80%)]\tLoss: 0.376748\n",
      "Train Epoch: 3 [49920/60032 (83%)]\tLoss: 0.306759\n",
      "Train Epoch: 3 [51840/60032 (86%)]\tLoss: 0.542979\n",
      "Train Epoch: 3 [53760/60032 (90%)]\tLoss: 0.430527\n",
      "Train Epoch: 3 [55680/60032 (93%)]\tLoss: 0.308133\n",
      "Train Epoch: 3 [57600/60032 (96%)]\tLoss: 0.480656\n",
      "Train Epoch: 3 [59520/60032 (99%)]\tLoss: 0.372593\n",
      "\n",
      "Test set: Average loss: 0.4519, Accuracy: 8402/10000 (84%)\n",
      "\n",
      "Train Epoch: 4 [0/60032 (0%)]\tLoss: 0.320581\n",
      "Train Epoch: 4 [1920/60032 (3%)]\tLoss: 0.631076\n",
      "Train Epoch: 4 [3840/60032 (6%)]\tLoss: 0.286490\n",
      "Train Epoch: 4 [5760/60032 (10%)]\tLoss: 0.523935\n",
      "Train Epoch: 4 [7680/60032 (13%)]\tLoss: 0.325305\n",
      "Train Epoch: 4 [9600/60032 (16%)]\tLoss: 0.596199\n",
      "Train Epoch: 4 [11520/60032 (19%)]\tLoss: 0.393038\n",
      "Train Epoch: 4 [13440/60032 (22%)]\tLoss: 0.504051\n",
      "Train Epoch: 4 [15360/60032 (26%)]\tLoss: 0.413913\n",
      "Train Epoch: 4 [17280/60032 (29%)]\tLoss: 0.378344\n",
      "Train Epoch: 4 [19200/60032 (32%)]\tLoss: 0.402758\n",
      "Train Epoch: 4 [21120/60032 (35%)]\tLoss: 0.542155\n",
      "Train Epoch: 4 [23040/60032 (38%)]\tLoss: 0.511467\n",
      "Train Epoch: 4 [24960/60032 (42%)]\tLoss: 0.435183\n",
      "Train Epoch: 4 [26880/60032 (45%)]\tLoss: 0.365397\n",
      "Train Epoch: 4 [28800/60032 (48%)]\tLoss: 0.245042\n",
      "Train Epoch: 4 [30720/60032 (51%)]\tLoss: 0.707835\n",
      "Train Epoch: 4 [32640/60032 (54%)]\tLoss: 0.371186\n",
      "Train Epoch: 4 [34560/60032 (58%)]\tLoss: 0.495418\n",
      "Train Epoch: 4 [36480/60032 (61%)]\tLoss: 0.379851\n",
      "Train Epoch: 4 [38400/60032 (64%)]\tLoss: 0.361252\n",
      "Train Epoch: 4 [40320/60032 (67%)]\tLoss: 0.341636\n",
      "Train Epoch: 4 [42240/60032 (70%)]\tLoss: 0.399882\n",
      "Train Epoch: 4 [44160/60032 (74%)]\tLoss: 0.444642\n",
      "Train Epoch: 4 [46080/60032 (77%)]\tLoss: 0.276158\n",
      "Train Epoch: 4 [48000/60032 (80%)]\tLoss: 0.367791\n",
      "Train Epoch: 4 [49920/60032 (83%)]\tLoss: 0.388704\n",
      "Train Epoch: 4 [51840/60032 (86%)]\tLoss: 0.388741\n",
      "Train Epoch: 4 [53760/60032 (90%)]\tLoss: 0.373146\n",
      "Train Epoch: 4 [55680/60032 (93%)]\tLoss: 0.465566\n",
      "Train Epoch: 4 [57600/60032 (96%)]\tLoss: 0.256960\n",
      "Train Epoch: 4 [59520/60032 (99%)]\tLoss: 0.446493\n",
      "\n",
      "Test set: Average loss: 0.4161, Accuracy: 8540/10000 (85%)\n",
      "\n",
      "Train Epoch: 5 [0/60032 (0%)]\tLoss: 0.417283\n",
      "Train Epoch: 5 [1920/60032 (3%)]\tLoss: 0.392888\n",
      "Train Epoch: 5 [3840/60032 (6%)]\tLoss: 0.361176\n",
      "Train Epoch: 5 [5760/60032 (10%)]\tLoss: 0.230830\n",
      "Train Epoch: 5 [7680/60032 (13%)]\tLoss: 0.252403\n",
      "Train Epoch: 5 [9600/60032 (16%)]\tLoss: 0.421771\n",
      "Train Epoch: 5 [11520/60032 (19%)]\tLoss: 0.280983\n",
      "Train Epoch: 5 [13440/60032 (22%)]\tLoss: 0.490155\n",
      "Train Epoch: 5 [15360/60032 (26%)]\tLoss: 0.339542\n",
      "Train Epoch: 5 [17280/60032 (29%)]\tLoss: 0.387946\n",
      "Train Epoch: 5 [19200/60032 (32%)]\tLoss: 0.422835\n",
      "Train Epoch: 5 [21120/60032 (35%)]\tLoss: 0.393878\n",
      "Train Epoch: 5 [23040/60032 (38%)]\tLoss: 0.422789\n",
      "Train Epoch: 5 [24960/60032 (42%)]\tLoss: 0.258963\n",
      "Train Epoch: 5 [26880/60032 (45%)]\tLoss: 0.599652\n",
      "Train Epoch: 5 [28800/60032 (48%)]\tLoss: 0.409271\n",
      "Train Epoch: 5 [30720/60032 (51%)]\tLoss: 0.383175\n",
      "Train Epoch: 5 [32640/60032 (54%)]\tLoss: 0.434074\n",
      "Train Epoch: 5 [34560/60032 (58%)]\tLoss: 0.568650\n",
      "Train Epoch: 5 [36480/60032 (61%)]\tLoss: 0.274109\n",
      "Train Epoch: 5 [38400/60032 (64%)]\tLoss: 0.581252\n",
      "Train Epoch: 5 [40320/60032 (67%)]\tLoss: 0.231442\n",
      "Train Epoch: 5 [42240/60032 (70%)]\tLoss: 0.302265\n",
      "Train Epoch: 5 [44160/60032 (74%)]\tLoss: 0.331525\n",
      "Train Epoch: 5 [46080/60032 (77%)]\tLoss: 0.509150\n",
      "Train Epoch: 5 [48000/60032 (80%)]\tLoss: 0.456699\n",
      "Train Epoch: 5 [49920/60032 (83%)]\tLoss: 0.446249\n",
      "Train Epoch: 5 [51840/60032 (86%)]\tLoss: 0.387580\n",
      "Train Epoch: 5 [53760/60032 (90%)]\tLoss: 0.260275\n",
      "Train Epoch: 5 [55680/60032 (93%)]\tLoss: 0.327271\n",
      "Train Epoch: 5 [57600/60032 (96%)]\tLoss: 0.361592\n",
      "Train Epoch: 5 [59520/60032 (99%)]\tLoss: 0.352609\n",
      "\n",
      "Test set: Average loss: 0.3858, Accuracy: 8621/10000 (86%)\n",
      "\n",
      "Train Epoch: 6 [0/60032 (0%)]\tLoss: 0.422520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [1920/60032 (3%)]\tLoss: 0.314785\n",
      "Train Epoch: 6 [3840/60032 (6%)]\tLoss: 0.340663\n",
      "Train Epoch: 6 [5760/60032 (10%)]\tLoss: 0.422981\n",
      "Train Epoch: 6 [7680/60032 (13%)]\tLoss: 0.252347\n",
      "Train Epoch: 6 [9600/60032 (16%)]\tLoss: 0.424351\n",
      "Train Epoch: 6 [11520/60032 (19%)]\tLoss: 0.441650\n",
      "Train Epoch: 6 [13440/60032 (22%)]\tLoss: 0.210421\n",
      "Train Epoch: 6 [15360/60032 (26%)]\tLoss: 0.485312\n",
      "Train Epoch: 6 [17280/60032 (29%)]\tLoss: 0.434715\n",
      "Train Epoch: 6 [19200/60032 (32%)]\tLoss: 0.425537\n",
      "Train Epoch: 6 [21120/60032 (35%)]\tLoss: 0.286713\n",
      "Train Epoch: 6 [23040/60032 (38%)]\tLoss: 0.256307\n",
      "Train Epoch: 6 [24960/60032 (42%)]\tLoss: 0.276407\n",
      "Train Epoch: 6 [26880/60032 (45%)]\tLoss: 0.415449\n",
      "Train Epoch: 6 [28800/60032 (48%)]\tLoss: 0.336917\n",
      "Train Epoch: 6 [30720/60032 (51%)]\tLoss: 0.434616\n",
      "Train Epoch: 6 [32640/60032 (54%)]\tLoss: 0.487135\n",
      "Train Epoch: 6 [34560/60032 (58%)]\tLoss: 0.409950\n",
      "Train Epoch: 6 [36480/60032 (61%)]\tLoss: 0.413578\n",
      "Train Epoch: 6 [38400/60032 (64%)]\tLoss: 0.432112\n",
      "Train Epoch: 6 [40320/60032 (67%)]\tLoss: 0.297041\n",
      "Train Epoch: 6 [42240/60032 (70%)]\tLoss: 0.346371\n",
      "Train Epoch: 6 [44160/60032 (74%)]\tLoss: 0.309028\n",
      "Train Epoch: 6 [46080/60032 (77%)]\tLoss: 0.356562\n",
      "Train Epoch: 6 [48000/60032 (80%)]\tLoss: 0.505663\n",
      "Train Epoch: 6 [49920/60032 (83%)]\tLoss: 0.245639\n",
      "Train Epoch: 6 [51840/60032 (86%)]\tLoss: 0.586482\n",
      "Train Epoch: 6 [53760/60032 (90%)]\tLoss: 0.455574\n",
      "Train Epoch: 6 [55680/60032 (93%)]\tLoss: 0.372845\n",
      "Train Epoch: 6 [57600/60032 (96%)]\tLoss: 0.316727\n",
      "Train Epoch: 6 [59520/60032 (99%)]\tLoss: 0.367968\n",
      "\n",
      "Test set: Average loss: 0.3864, Accuracy: 8577/10000 (86%)\n",
      "\n",
      "Train Epoch: 7 [0/60032 (0%)]\tLoss: 0.298352\n",
      "Train Epoch: 7 [1920/60032 (3%)]\tLoss: 0.446078\n",
      "Train Epoch: 7 [3840/60032 (6%)]\tLoss: 0.294628\n",
      "Train Epoch: 7 [5760/60032 (10%)]\tLoss: 0.283045\n",
      "Train Epoch: 7 [7680/60032 (13%)]\tLoss: 0.451922\n",
      "Train Epoch: 7 [9600/60032 (16%)]\tLoss: 0.273546\n",
      "Train Epoch: 7 [11520/60032 (19%)]\tLoss: 0.208236\n",
      "Train Epoch: 7 [13440/60032 (22%)]\tLoss: 0.433891\n",
      "Train Epoch: 7 [15360/60032 (26%)]\tLoss: 0.163802\n",
      "Train Epoch: 7 [17280/60032 (29%)]\tLoss: 0.261867\n",
      "Train Epoch: 7 [19200/60032 (32%)]\tLoss: 0.397924\n",
      "Train Epoch: 7 [21120/60032 (35%)]\tLoss: 0.285559\n",
      "Train Epoch: 7 [23040/60032 (38%)]\tLoss: 0.353615\n",
      "Train Epoch: 7 [24960/60032 (42%)]\tLoss: 0.607414\n",
      "Train Epoch: 7 [26880/60032 (45%)]\tLoss: 0.283823\n",
      "Train Epoch: 7 [28800/60032 (48%)]\tLoss: 0.475276\n",
      "Train Epoch: 7 [30720/60032 (51%)]\tLoss: 0.295559\n",
      "Train Epoch: 7 [32640/60032 (54%)]\tLoss: 0.449797\n",
      "Train Epoch: 7 [34560/60032 (58%)]\tLoss: 0.373346\n",
      "Train Epoch: 7 [36480/60032 (61%)]\tLoss: 0.276718\n",
      "Train Epoch: 7 [38400/60032 (64%)]\tLoss: 0.253333\n",
      "Train Epoch: 7 [40320/60032 (67%)]\tLoss: 0.211243\n",
      "Train Epoch: 7 [42240/60032 (70%)]\tLoss: 0.241143\n",
      "Train Epoch: 7 [44160/60032 (74%)]\tLoss: 0.315217\n",
      "Train Epoch: 7 [46080/60032 (77%)]\tLoss: 0.408760\n",
      "Train Epoch: 7 [48000/60032 (80%)]\tLoss: 0.244640\n",
      "Train Epoch: 7 [49920/60032 (83%)]\tLoss: 0.377927\n",
      "Train Epoch: 7 [51840/60032 (86%)]\tLoss: 0.273801\n",
      "Train Epoch: 7 [53760/60032 (90%)]\tLoss: 0.165641\n",
      "Train Epoch: 7 [55680/60032 (93%)]\tLoss: 0.434567\n",
      "Train Epoch: 7 [57600/60032 (96%)]\tLoss: 0.511446\n",
      "Train Epoch: 7 [59520/60032 (99%)]\tLoss: 0.226345\n",
      "\n",
      "Test set: Average loss: 0.3563, Accuracy: 8725/10000 (87%)\n",
      "\n",
      "Train Epoch: 8 [0/60032 (0%)]\tLoss: 0.241056\n",
      "Train Epoch: 8 [1920/60032 (3%)]\tLoss: 0.311629\n",
      "Train Epoch: 8 [3840/60032 (6%)]\tLoss: 0.344571\n",
      "Train Epoch: 8 [5760/60032 (10%)]\tLoss: 0.479836\n",
      "Train Epoch: 8 [7680/60032 (13%)]\tLoss: 0.136833\n",
      "Train Epoch: 8 [9600/60032 (16%)]\tLoss: 0.138072\n",
      "Train Epoch: 8 [11520/60032 (19%)]\tLoss: 0.364487\n",
      "Train Epoch: 8 [13440/60032 (22%)]\tLoss: 0.410191\n",
      "Train Epoch: 8 [15360/60032 (26%)]\tLoss: 0.314750\n",
      "Train Epoch: 8 [17280/60032 (29%)]\tLoss: 0.274586\n",
      "Train Epoch: 8 [19200/60032 (32%)]\tLoss: 0.388485\n",
      "Train Epoch: 8 [21120/60032 (35%)]\tLoss: 0.404165\n",
      "Train Epoch: 8 [23040/60032 (38%)]\tLoss: 0.353498\n",
      "Train Epoch: 8 [24960/60032 (42%)]\tLoss: 0.452908\n",
      "Train Epoch: 8 [26880/60032 (45%)]\tLoss: 0.467454\n",
      "Train Epoch: 8 [28800/60032 (48%)]\tLoss: 0.331813\n",
      "Train Epoch: 8 [30720/60032 (51%)]\tLoss: 0.256254\n",
      "Train Epoch: 8 [32640/60032 (54%)]\tLoss: 0.220278\n",
      "Train Epoch: 8 [34560/60032 (58%)]\tLoss: 0.314447\n",
      "Train Epoch: 8 [36480/60032 (61%)]\tLoss: 0.282671\n",
      "Train Epoch: 8 [38400/60032 (64%)]\tLoss: 0.318154\n",
      "Train Epoch: 8 [40320/60032 (67%)]\tLoss: 0.137458\n",
      "Train Epoch: 8 [42240/60032 (70%)]\tLoss: 0.473071\n",
      "Train Epoch: 8 [44160/60032 (74%)]\tLoss: 0.307409\n",
      "Train Epoch: 8 [46080/60032 (77%)]\tLoss: 0.382473\n",
      "Train Epoch: 8 [48000/60032 (80%)]\tLoss: 0.365147\n",
      "Train Epoch: 8 [49920/60032 (83%)]\tLoss: 0.311387\n",
      "Train Epoch: 8 [51840/60032 (86%)]\tLoss: 0.371184\n",
      "Train Epoch: 8 [53760/60032 (90%)]\tLoss: 0.337132\n",
      "Train Epoch: 8 [55680/60032 (93%)]\tLoss: 0.307658\n",
      "Train Epoch: 8 [57600/60032 (96%)]\tLoss: 0.356947\n",
      "Train Epoch: 8 [59520/60032 (99%)]\tLoss: 0.267511\n",
      "\n",
      "Test set: Average loss: 0.3350, Accuracy: 8803/10000 (88%)\n",
      "\n",
      "Train Epoch: 9 [0/60032 (0%)]\tLoss: 0.362250\n",
      "Train Epoch: 9 [1920/60032 (3%)]\tLoss: 0.191756\n",
      "Train Epoch: 9 [3840/60032 (6%)]\tLoss: 0.301726\n",
      "Train Epoch: 9 [5760/60032 (10%)]\tLoss: 0.238114\n",
      "Train Epoch: 9 [7680/60032 (13%)]\tLoss: 0.348836\n",
      "Train Epoch: 9 [9600/60032 (16%)]\tLoss: 0.327367\n",
      "Train Epoch: 9 [11520/60032 (19%)]\tLoss: 0.448865\n",
      "Train Epoch: 9 [13440/60032 (22%)]\tLoss: 0.283938\n",
      "Train Epoch: 9 [15360/60032 (26%)]\tLoss: 0.383303\n",
      "Train Epoch: 9 [17280/60032 (29%)]\tLoss: 0.368232\n",
      "Train Epoch: 9 [19200/60032 (32%)]\tLoss: 0.337531\n",
      "Train Epoch: 9 [21120/60032 (35%)]\tLoss: 0.305904\n",
      "Train Epoch: 9 [23040/60032 (38%)]\tLoss: 0.115637\n",
      "Train Epoch: 9 [24960/60032 (42%)]\tLoss: 0.398041\n",
      "Train Epoch: 9 [26880/60032 (45%)]\tLoss: 0.312263\n",
      "Train Epoch: 9 [28800/60032 (48%)]\tLoss: 0.259348\n",
      "Train Epoch: 9 [30720/60032 (51%)]\tLoss: 0.254801\n",
      "Train Epoch: 9 [32640/60032 (54%)]\tLoss: 0.171424\n",
      "Train Epoch: 9 [34560/60032 (58%)]\tLoss: 0.453892\n",
      "Train Epoch: 9 [36480/60032 (61%)]\tLoss: 0.226205\n",
      "Train Epoch: 9 [38400/60032 (64%)]\tLoss: 0.352850\n",
      "Train Epoch: 9 [40320/60032 (67%)]\tLoss: 0.389545\n",
      "Train Epoch: 9 [42240/60032 (70%)]\tLoss: 0.228469\n",
      "Train Epoch: 9 [44160/60032 (74%)]\tLoss: 0.293635\n",
      "Train Epoch: 9 [46080/60032 (77%)]\tLoss: 0.344445\n",
      "Train Epoch: 9 [48000/60032 (80%)]\tLoss: 0.254179\n",
      "Train Epoch: 9 [49920/60032 (83%)]\tLoss: 0.337162\n",
      "Train Epoch: 9 [51840/60032 (86%)]\tLoss: 0.391675\n",
      "Train Epoch: 9 [53760/60032 (90%)]\tLoss: 0.489813\n",
      "Train Epoch: 9 [55680/60032 (93%)]\tLoss: 0.259097\n",
      "Train Epoch: 9 [57600/60032 (96%)]\tLoss: 0.302920\n",
      "Train Epoch: 9 [59520/60032 (99%)]\tLoss: 0.349977\n",
      "\n",
      "Test set: Average loss: 0.3500, Accuracy: 8739/10000 (87%)\n",
      "\n",
      "Train Epoch: 10 [0/60032 (0%)]\tLoss: 0.389186\n",
      "Train Epoch: 10 [1920/60032 (3%)]\tLoss: 0.174746\n",
      "Train Epoch: 10 [3840/60032 (6%)]\tLoss: 0.218334\n",
      "Train Epoch: 10 [5760/60032 (10%)]\tLoss: 0.267636\n",
      "Train Epoch: 10 [7680/60032 (13%)]\tLoss: 0.214168\n",
      "Train Epoch: 10 [9600/60032 (16%)]\tLoss: 0.164149\n",
      "Train Epoch: 10 [11520/60032 (19%)]\tLoss: 0.245106\n",
      "Train Epoch: 10 [13440/60032 (22%)]\tLoss: 0.214533\n",
      "Train Epoch: 10 [15360/60032 (26%)]\tLoss: 0.265893\n",
      "Train Epoch: 10 [17280/60032 (29%)]\tLoss: 0.260857\n",
      "Train Epoch: 10 [19200/60032 (32%)]\tLoss: 0.235501\n",
      "Train Epoch: 10 [21120/60032 (35%)]\tLoss: 0.451156\n",
      "Train Epoch: 10 [23040/60032 (38%)]\tLoss: 0.352485\n",
      "Train Epoch: 10 [24960/60032 (42%)]\tLoss: 0.285316\n",
      "Train Epoch: 10 [26880/60032 (45%)]\tLoss: 0.173021\n",
      "Train Epoch: 10 [28800/60032 (48%)]\tLoss: 0.294579\n",
      "Train Epoch: 10 [30720/60032 (51%)]\tLoss: 0.177234\n",
      "Train Epoch: 10 [32640/60032 (54%)]\tLoss: 0.221165\n",
      "Train Epoch: 10 [34560/60032 (58%)]\tLoss: 0.321256\n",
      "Train Epoch: 10 [36480/60032 (61%)]\tLoss: 0.142393\n",
      "Train Epoch: 10 [38400/60032 (64%)]\tLoss: 0.359928\n",
      "Train Epoch: 10 [40320/60032 (67%)]\tLoss: 0.172721\n",
      "Train Epoch: 10 [42240/60032 (70%)]\tLoss: 0.338109\n",
      "Train Epoch: 10 [44160/60032 (74%)]\tLoss: 0.193744\n",
      "Train Epoch: 10 [46080/60032 (77%)]\tLoss: 0.267439\n",
      "Train Epoch: 10 [48000/60032 (80%)]\tLoss: 0.352436\n",
      "Train Epoch: 10 [49920/60032 (83%)]\tLoss: 0.426261\n",
      "Train Epoch: 10 [51840/60032 (86%)]\tLoss: 0.217095\n",
      "Train Epoch: 10 [53760/60032 (90%)]\tLoss: 0.392689\n",
      "Train Epoch: 10 [55680/60032 (93%)]\tLoss: 0.354450\n",
      "Train Epoch: 10 [57600/60032 (96%)]\tLoss: 0.372710\n",
      "Train Epoch: 10 [59520/60032 (99%)]\tLoss: 0.393544\n",
      "\n",
      "Test set: Average loss: 0.3251, Accuracy: 8830/10000 (88%)\n",
      "\n",
      "Wall time: 13min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, model, device, federated_train_loader, optimizer, epoch)\n",
    "    test(args, model, device, test_loader)\n",
    "\n",
    "if (args.save_model):\n",
    "    torch.save(model.state_dict(), \"fmnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:vw0 #objects:7>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vw0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:vw0 #objects:7>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
